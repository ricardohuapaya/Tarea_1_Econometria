---
title: "Solución Tarea 2"
author: "Integrantes: María Fernanda Villalobos Barboza B78304, \nRicardo Huapaya Rey B83936, \nSebasthián Valverde Martínez B98083, \nSebastian Mora Rojas B95205\n"
date: '`r format(Sys.Date(), "%d %b, %Y")`'
output:
  html_document: default
  word_document: default
theme: "journal"
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, echo=FALSE, results='hide', message=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(readxl)
library(dplyr)
library(tseries)
library(stargazer)
library(normtest)
library(skedastic)
library(car)
library(olsrr)

setwd("~/UCR/Tarea_2_Econometria")

cigs = read_excel("Data/CigarettesB.xlsx")

energy = read_excel("Data/Electricity1970.xlsx")

house = read_excel("Data/HousePrices.xlsx")

datos_reg <- select(energy, Costo= ln_COST, Produccion = ln_output, 
                    Trabajo= ln_labor, Capital= ln_capital, Combustible= fuel)
```

En este presente documento se procede a realizar un análisis econométrico de diversas bases de datos de interés.
Para ello se selecionaron las bases:

-   2.2 CigarettesB: Cigarette Consumption Data

-   2.6 Electricity1970: Cost Function of Electricity Producers 1970

-   2.10 HousePrices: House Prices in the City of Windsor, Canada.

La estructura del documento es de un análisis individual en el orden mencionado previamente.
Para así al final discutir en una última sección las conclusiones de cada análisis.
El codigo del codigo se encuentra en el siguiente [repositorio](https://github.com/ricardohuapaya/Tarea_1_Econometria).

## 1. Análisis Cigarettes Data

Para la base de datos 2.2 tomaremos la variable `PACKS` como nuestra variable dependiente que será analizada.
Esta variable representa el número de paquetes consumidos por personas mayores de 16 años en casa Estado; así nuestro modelo propuesto para el primer análisis sería de la forma:

$$
ln(PACKS) = \beta_{0}+\beta_{1}ln(price)+\beta_{2}income+\mu
$$

### 1.1 Regresión

Con el fin de analizar la regresión lineal de nuestras variables, utilizaremos el siguiente código:

```{r, warning = FALSE}
linear.cigs <-lm(PACKS ~ price+income, data=cigs)
```

La regresión nos muestra que en promedio se consumiría $4.3$ paquetes de cigarillos si el precio y los ingresos fueran $0$.
En este otro caso note que dada la definición del modelo $\beta_{1}$ es un indicador de Elasticidad precio de la demanda de cigarrillos.
Considere que al ser mayor a uno no sigue la intuición económica incial que los cigarrillos son ineslásticos.

```{r, echo=TRUE, warning=FALSE}
stargazer(linear.cigs, type = "text", title = "Cuadro #1: Resultados Regresión")
coef = coefficients(linear.cigs)
```

### 1.2 Pruebas t

Utilizando la misma función que en la sección anterior, y con el cuadro 1 se obtiene la información necesaria para obtener los resultados de la prueba $t$.

Tomando $H_{0}: \beta_{1}=0$ (Precio no tiene efecto en consumo) La prueba $t$ realizada para el precio nos devuelve un P-value de 0.000168, entonces con un nivel de significancia del 5% podemos rechazar la hipotesis nula donde el precio del paquete no afecta el consumo.

Tomando $H_{0}: \beta_{2}=0$ (Ingreso no tiene efecto en consumo) La prueba t realizada para el ingreso nos devuelve un P-Value de 0.386 el cual, entonces con un nivel de significancia del 5% podemos no podemos rechazar la hipotesis nula donde el precio del paquete no afecta el consumo.

### 1.3 Pruebas F

Utilizando la misma función que en la pregunta anterior, y con el cuadro 1 se obtiene la información necesaria para obtener los resultados de la prueba $f$.

Tomando una prueba de significancia conjunta tal que nuestra hipotesis nula sea; $H_{0}: \beta_{1}= \beta_{2}=0$.
La prueba $f$ conjunta nos devuelve un P-value de 0.0004168, entonces con un nivel de significancia del 5% se rechaza la hipotesis nula conjunta de que el precio y el ingreso no afectan el consumo.

### 1.4 Prubas Generales Evaluación de Supuestos MCRL

Para esta sección procedemos a analizar los resultados de la secciones 1.1-1.3, para ello consideraremos los resultados y en la siguiente sección procederemos a intentar corregir los efectos mostrados o justificar las acciones pasivas frente a ellos.

#### Jarque-Bera

Considere la prueba de normalidad Jarque-Bera, para ello podemos observar inicialmente la distribución de los residuos de nuestra regresión `linear.cigs`.
Note que empiricamente, aparenta tener una distribución normal.

```{r Historgram, echo=FALSE, message=TRUE}

hist(residuals(linear.cigs))
```

Con esta información podemos correr la prueba de Jarque-Bera, para ello parta de la siguiente hipotesis nula donde,

$$
H_{0}: JB\sim \overline{\chi^{2}}_{2 \, g.l.}
$$

```{r Jarque-Bera, echo=FALSE}

jarque.bera.test(residuals(linear.cigs))
```

El codigo nos da un resultado de con el p-value de 0.86, por lo que con un nivel de significancia del 5% no podemos rechazar $H_{0}$.
Por ello concluimos que los residuos se distribuyen de forma normal.

#### Prueba de Heterocedasticidad (White)

Considere ahora una prueba de Heterocedasticidad, en este caso al ser dos variables explicativas se puede aplicar la regresión la prueba de White con **interacciones**.
Para ello la hipotesis nula se especifica como,

$$
H_{0}: \nexists \, Heterocedasticidad
$$

Corremos la prueba la cual nos da el siguiente resultado,

```{r White, echo=FALSE}
white.cigs <- as.data.frame(white_lm(linear.cigs, interactions = TRUE))

stargazer(white.cigs, type ="text",title = "Cuadro #2: Prueba de Heterocedastidad", summary = FALSE)

```

Observando los resultados de la prueba se obtiene que con un nivel de significancia del 5%, se tiene un p-value de 0.008 por lo que Rechazamos la hipotesis nula y confirmamos que sí existe la presencia de heterocedasticidad en el modelo.

#### Prueba de Haussman

#### Prueba de Multicolinealidad

Inicialmente considere dentro de nuestra correlación si ha de existir un problema de multicolinealidad perfecta, corremos un codigo en el modelo para observar si este detecta algun error.

```{r}
linear.cigs <-lm(PACKS ~ price+income, data=cigs, singular.ok = FALSE)
```

Note que por el momento no tenemos un problema de multicolinealidad perfecta.
Sin embargo, es necesario realizar un analisis más de este.
Considere un analisis de multicolinealidad, para ello considere los siguientes factores, la $R^{2}$ a un nivel de, vista en el Cuadro \#1; y la matriz de correlaciones entre variables explicativas.

```{r, echo=TRUE}


cor(cigs$price, cigs$income, method="pearson")
cor(cigs$price, cigs$PACKS, method="pearson")
cor(cigs$income, cigs$PACKS, method="pearson")

```

Visto los resultados de la matriz, vemos que si existe alta correlación entre varias variables, sin embargo, nada mayor a 8.
Por ellos ahora usaremos el analisis del indice K.

Procedemos en analsis del indice K donde sabemos que,

$$
K= \frac{\max_{valor \, propio}X'X}{\min_{valor \, propio}X'X}
$$

Donde el Indice K (IC) es $\sqrt{K}$, donde si

-   Si 10 \< IC \< 30 hay multicolinealidad modera fuerte.

-   Si IC\> 30 hay un problema serio de multicolinealidad.

```{r}

#Se crea la matriz de variables explicativas

X <- as.matrix(cbind(cigs$price,cigs$income))

#Se computa X'X

X_prima_X <- t(X)%*%X

#Se obtienen los valores propis de la matriz X'X con la función eigen (base de R), se usa la opción only.values = TRUE para que solo brinde los valores propios y no sus vectores asociados
valores_propios<-eigen(X_prima_X, only.values = TRUE)

#Se computa el índice de condición K
indice_condicion_k<-sqrt(max(valores_propios$values))/sqrt(min(valores_propios$values))

indice_condicion_k
```

El Indice K nos da un númeri superior a 30, por lo que se tiene un problema serio de multicolinealidad.

#### Prueba de Autocorrelación (Durbin y Watson)

Vamos a realizar finalmente una prueba que estudie la correlación de nuestro modelo, para ello recuerde la formula de estadistico $d$

$$
d=\frac{\sum_{t=2}^{T}(\hat{u_{t}}-\hat{u_{t-1}})^{2}}{\sum_{t=1}^{T}\hat{u_{t}^{2}}}
$$

Para ello considere la siguiente hipotesis nula,

$$
H_{0}: d=2 \implies \nexists \, autocorrelación
$$

```{r, echo=FALSE}

durbinWatsonTest(linear.cigs)


```

Para este caso con $n=46$ y $k=2$, tenemos que dentro de nuestro mapa.

$$
d_{L} = 1.48 \, \& \, d_{U} = 1.56 
$$

Como nuestro estadistico nos dio 2.32, note que $2.32 < (4-1.56 )$, asi entonces no se puede rechazar la hipotesis nula y concluimos que no hay presencia de autocorrelación.

### 1.5 Corrección a las Pruebas

### 1.6 Comparación

## 2. Análisis Energy Data

Para la base de datos 2.6 tomaremos el la variable `Costo` como nuestra variable dependiente que será analizada.
Esta variable representa el costo en dolares por cada mil kwh.
Las variables explicativas tomadas son el salario promedio de la firma, el indice de capital, el precio de combustible y el output final en millones de kwh.
A partir de estas variables, la regresión sera calculada con los logaritmos naturales de las variables costo, producción, trabajo y capital

$$
ln(Costo) = \beta_{0}+ \beta_{1}ln(producción)+\beta_{2}ln(trabajo)+\beta_{3}ln(capital)+\beta_{4}combustible +\mu
$$

### 2.1 Regresión Lineal

Con el fin de analizar la regresión lineal de nuestras variables, utilizaremos el siguiente codigo:

```{r, warning = FALSE}
linear.energy <- lm( Costo ~ Produccion + Trabajo + Capital + Combustible, data= datos_reg)
```

```{r, echo=FALSE, warning=FALSE}
stargazer(linear.energy, type = "text", title = "Cuadro #3: Resultados Regresión")
coef2 = coefficients(linear.energy)
```

Con todo lo demas constante se pueden realizar las siguientes interpretacions de los coeficientes.

Para el $\beta_{1}$ se interpreta como la elasticidad del costo a producción, si la producción incrementa en 1% se espera que los costos aumenten en 0.84%.

Para el $\beta_{3}$ se interpreta como la elasticidad del costo a capital, si el capital incrementa en 1% se espera que los costos aumenten en 0.18%.

Para el $\beta_{4}$ se interpreta como la semielasticidad del costo respecto al combustible, si la producción incrementa en un dolar se espera que los costos aumenten en 0.023%

### 2.2 Pruebas t

Utilizando la misma función que en la pregunta anterior, y con el cuadro 2 se obtiene la información necesaria para obtener los resultados de la prueba $t$.
Tomando $H_{0}: \beta_{1}=0$ (Producción no tiene efecto en los Costos) La prueba $t$ realizada para la producción nos devuelve un P-value que tiende a 0, entonces con un nivel de significancia del 5% podemos rechazar la hipotesis nula donde la producción no afecta los costos.

Tomando $H_{0}: \beta_{2}=0$ (Trabajo no tiene efecto en los Costos) La prueba $t$ realizada para la producción nos devuelve un P-value de 0.7515, entonces no se se puede rechazar la hipotesis nula, por lo tanto el trabajo no tiene efecto sobre los costos.

Tomando $H_{0}: \beta_{3}=0$ (Capital no tiene efecto en los Costos) La prueba $t$ realizada para la producción nos devuelve un P-value de 0.0496, entonces con un nivel de significancia del 5% podemos rechazar la hipotesis nula donde el capital no afecta los costos.

Tomando $H_{0}: \beta_{4}=0$ (Combustible no tiene efecto en los Costos) La prueba $t$ realizada para la producción nos devuelve un P-value que tiende a 0, entonces con un nivel de significancia del 5% podemos rechazar la hipotesis nula donde la producción no afecta los costos.

### 2.3 Prueba F

Utilizando la misma función que en la pregunta anterior, y con el cuadro 2 se obtiene la información necesaria para obtener los resultados de la prueba F.
Tomando una prueba de significancia conjunta tal que nuestra hipotesis nula sea; $H_{0}: \beta_{1}= \beta_{2}=\beta_{3}= \beta_{4}=0$.
La prueba F conjunta nos devuelve un P-value que tiende a 0, entonces con un nivel de significancia del 5% se rechaza la hipotesis nula conjunta de que los B´s no afectan los costos.

Interpretando la prueba F de significancia conjunta del modelo con la función summary donde la Ho: B´s(en conjunto)= 0 se puede afirmar que los coeficientes de las variables explicativas no son 0 ya que el p-value asociado a la prueba es practicamente 0.

### 2.4 Prubas Generales Evaluación de Supuestos MCRL

Para esta sección procedemos a analizar los resultados de la secciones 2.1-2.3, para ello consideraremos los resultados y en la siguiente sección procederemos a intentar corregir los efectos mostrados o justificar las acciones pasivas frente a ellos.

#### Jarque-Bera

Considere la prueba de normalidad Jarque-Bera, para ello podemos observar inicialmente la distribución de los residuos de nuestra regresión `linear.enerfy`.
Note que empiricamente, no aparenta tener una distribución normal.

```{r Historgram 2, echo=FALSE, message=TRUE}

hist(residuals(linear.energy))
```

Con esta información podemos correr la prueba de Jarque-Bera, para ello parta de la siguiente hipotesis nula donde,

$$
H_{0}: JB\sim \overline{\chi^{2}}_{2 \, g.l.}
$$

```{r Jarque-Bera 2, echo=FALSE}

jarque.bera.test(residuals(linear.energy))
```

El codigo nos da un resultado de con el p-value que tiende a 0, por lo que con un nivel de significancia del 5% podemos rechazar $H_{0}$.
Por ello concluimos que los residuos no se distribuyen de forma normal.

#### Prueba de Heterocedasticidad (White)

Considere ahora una prueba de Heterocedasticidad, en este caso al ser más de dos variables explicativas se debería aplicar la regresión la prueba de White sin **terminos cruzados**.
Para ello la hipotesis nula se especifica como,

$$
H_{0}: \nexists \, Heterocedasticidad
$$

Corremos la prueba la cual nos da el siguiente resultado,

```{r White 2, echo=FALSE}
white.energy <- as.data.frame(white_lm(linear.energy, interactions = FALSE))

stargazer(white.energy, type ="text",title = "Cuadro #4: Prueba de Heterocedastidad", summary = FALSE)


```

Observando los resultados de la prueba se obtiene que con un nivel de significancia del 5%, a partir de la prueba de White sin terminos cruzados se obtiene un p-value que tiende a 0 por lo que se rechaza la $H_{0}$ y se confirma la evidencia de heterocedasticidad.

#### Prueba de Multicolinealidad

Inicialmente considere dentro de nuestra correlación si ha de existir un problema de multicolinealidad perfecta, corremos un codigo en el modelo para observar si este detecta algun error.

```{r, echo=TRUE}
lm( Costo ~ Produccion + Trabajo + Capital + Combustible, data= datos_reg, singular.ok = FALSE)
```

Note que por el momento no tenemos un problema de multicolinealidad perfecta.
Sin embargo, es necesario realizar un analisis más de este.
Considere un analisis de multicolinealidad, para ello considere los siguientes factores, la $R^{2}$ a un nivel de 0.98, vista en el Cuadro \#3; y la matriz de correlaciones entre variables explicativas.

```{r, echo=TRUE}

cor(datos_reg$Produccion, datos_reg$Trabajo ,method="pearson")
cor(datos_reg$Produccion, datos_reg$Capital ,method="pearson")
cor(datos_reg$Produccion, datos_reg$Combustible ,method="pearson")
cor(datos_reg$Produccion, datos_reg$Costo ,method="pearson")


```

Visto los resultados de la matriz, vemos que si existe naja correlación entre varias variablesPor ellos ahora usaremos el analisis del indice K.

Procedemos en analsis del indice K donde sabemos que,

$$
K= \frac{\max_{valor \, propio}X'X}{\min_{valor \, propio}X'X}
$$

Donde el Indice K (IC) es $\sqrt{K}$, donde si

-   Si 10 \< IC \< 30 hay multicolinealidad modera fuerte.

-   Si IC\> 30 hay un problema serio de multicolinealidad.

```{r}

#Se crea la matriz de variables explicativas

X <- as.matrix(cbind(datos_reg$Produccion, datos_reg$Trabajo, datos_reg$Capital, datos_reg$Combustible))

#Se computa X'X

X_prima_X <- t(X)%*%X

#Se obtienen los valores propis de la matriz X'X con la función eigen (base de R), se usa la opción only.values = TRUE para que solo brinde los valores propios y no sus vectores asociados
valores_propios<-eigen(X_prima_X, only.values = TRUE)

#Se computa el índice de condición K
indice_condicion_k<-sqrt(max(valores_propios$values))/sqrt(min(valores_propios$values))

indice_condicion_k
```

El Indice K nos da un número extremadamente alto, por lo que se tiene un problema muy serio de multicolinealidad.

#### Prueba de Autocorrelación (Durbin y Watson)

Vamos a realizar finalmente una prueba que estudie la correlación de nuestro modelo, para ello recuerde la formula de estadistico $d$

$$
d=\frac{\sum_{t=2}^{T}(\hat{u_{t}}-\hat{u_{t-1}})^{2}}{\sum_{t=1}^{T}\hat{u_{t}^{2}}}
$$

Para ello considere la siguiente hipotesis nula,

$$
H_{0}: d=2 \implies \nexists \, autocorrelación
$$

```{r, echo=FALSE}

durbinWatsonTest(linear.energy)


```

Para este caso con $n=158$ y $k=4$, tenemos que dentro de nuestro mapa.

$$
d_{L} = 1.70 \, \& \, d_{U} = 1.78
$$

Como nuestro estadistico nos dio 1.55, note que $1.55 < 1.70 )$, asi entonces se puede rechazar la hipotesis nula y concluimos que hay presencia de autocorrelación.

### 2.5 Corrección a las Pruebas

### 2.6 Comparación

## 3. Análisis Housing Data

Para la base de datos 2.10 tomaremos el la variable `PRICE`como nuestra variable dependiente que será analizada.
Esta variable representa el costo en dolares de las viviendas.
Las variables explicativas tomadas son el numero de cuartos, el tamaño del terreno y la cantidad de baños.

$$
Price = \beta_{0}+ \beta_{1}lotsize+\beta_{2}bedrooms+\beta_{3}bathrooms+\mu
$$

### 3.1 Regresión Lineal

Con el fin de analizar la regresión lineal de nuestras variables, utilizaremos el siguiente codigo:

```{r, warning = FALSE}
linear.house <- lm( PRICE ~ lotsize + bedrooms + bathrooms, data= house)
```

```{r, echo=FALSE, warning=FALSE}
stargazer(linear.house, type = "text", title = "Cuadro #5: Resultados Regresión")
coef3 = coefficients(linear.house)
```

Con todo lo demas constante se pueden realizar las siguientes interpretacions de los coeficientes.

Para el $\beta_{1}$ se interpreta como la elasticidad del costo a producción, si la producción incrementa en 1% se espera que los costos aumenten en 0.84%.

Para el $\beta_{3}$ se interpreta como la elasticidad del costo a capital, si el capital incrementa en 1% se espera que los costos aumenten en 0.18%.

Para el $\beta_{4}$ se interpreta como la semielasticidad del costo respecto al combustible, si la producción incrementa en un dolar se espera que los costos aumenten en 0.023%

### 3.2 Pruebas t

Utilizando la misma función que en la pregunta anterior, y con el cuadro 5 se obtiene la información necesaria para obtener los resultados de la prueba $t$.

Tomando $H_{0}: \beta_{1}=0$ (Producción no tiene efecto en los Costos) La prueba $t$ realizada para la producción nos devuelve un P-value que tiende a 0, entonces con un nivel de significancia del 5% podemos rechazar la hipotesis nula donde la producción no afecta los costos.

Tomando $H_{0}: \beta_{2}=0$ (Trabajo no tiene efecto en los Costos) La prueba $t$ realizada para la producción nos devuelve un P-value de 0.7515, entonces no se se puede rechazar la hipotesis nula, por lo tanto el trabajo no tiene efecto sobre los costos.

Tomando $H_{0}: \beta_{3}=0$ (Capital no tiene efecto en los Costos) La prueba $t$ realizada para la producción nos devuelve un P-value de 0.0496, entonces con un nivel de significancia del 5% podemos rechazar la hipotesis nula donde el capital no afecta los costos.

Tomando $H_{0}: \beta_{4}=0$ (Combustible no tiene efecto en los Costos) La prueba $t$ realizada para la producción nos devuelve un P-value que tiende a 0, entonces con un nivel de significancia del 5% podemos rechazar la hipotesis nula donde la producción no afecta los costos.

### 3.3 Prueba F

Utilizando la misma función que en la pregunta anterior, y con el cuadro 2 se obtiene la información necesaria para obtener los resultados de la prueba F.
Tomando una prueba de significancia conjunta tal que nuestra hipotesis nula sea; $H_{0}: \beta_{1}= \beta_{2}=\beta_{3}= \beta_{4}=0$.
La prueba F conjunta nos devuelve un P-value que tiende a 0, entonces con un nivel de significancia del 5% se rechaza la hipotesis nula conjunta de que los B´s no afectan los costos.

Interpretando la prueba F de significancia conjunta del modelo con la función summary donde la Ho: B´s(en conjunto)= 0 se puede afirmar que los coeficientes de las variables explicativas no son 0 ya que el p-value asociado a la prueba es practicamente 0.

### 3.4 Prubas Generales Evaluación de Supuestos MCRL

Para esta sección procedemos a analizar los resultados de la secciones 3.1-3.3, para ello consideraremos los resultados y en la siguiente sección procederemos a intentar corregir los efectos mostrados o justificar las acciones pasivas frente a ellos.

#### Jarque-Bera

Considere la prueba de normalidad Jarque-Bera, para ello podemos observar inicialmente la distribución de los residuos de nuestra regresión `linear.enerfy`.
Note que empiricamente, no aparenta tener una distribución normal.

```{r Historgram 3, echo=FALSE, message=TRUE}

hist(residuals(linear.house)/50000)
```

Con esta información podemos correr la prueba de Jarque-Bera, para ello parta de la siguiente hipotesis nula donde,

$$
H_{0}: JB\sim \overline{\chi^{2}}_{2 \, g.l.}
$$

```{r Jarque-Bera 3, echo=FALSE}

jarque.bera.test(residuals(linear.house)/50000)
```

El codigo nos da un resultado de con el p-value que tiende a 0, por lo que con un nivel de significancia del 5% podemos rechazar $H_{0}$.
Por ello concluimos que los residuos no se distribuyen de forma normal.

#### Prueba de Heterocedasticidad (White)

Considere ahora una prueba de Heterocedasticidad, en este caso al ser más de dos variables explicativas se debería aplicar la regresión la prueba de White sin **terminos cruzados**.
Para ello la hipotesis nula se especifica como,

$$
H_{0}: \nexists \, Heterocedasticidad
$$

Corremos la prueba la cual nos da el siguiente resultado,

```{r White3, echo=FALSE}
white.house<- as.data.frame(white_lm(linear.house, interactions = FALSE))

stargazer(white.house, type ="text",title = "Cuadro #6: Prueba de Heterocedastidad", summary = FALSE)

white.house
```

Observando los resultados de la prueba se obtiene que con un nivel de significancia del 5%, a partir de la prueba de White sin terminos cruzados se obtiene un p-value que tiende a 0 por lo que se rechaza la $H_{0}$ y se confirma la evidencia de heterocedasticidad.

#### Prueba de Multicolinealidad

Inicialmente considere dentro de nuestra correlación si ha de existir un problema de multicolinealidad perfecta, corremos un codigo en el modelo para observar si este detecta algun error.

```{r, echo=TRUE}
lm( PRICE ~ lotsize + bedrooms + bathrooms, data= house, singular.ok = FALSE)
```

Note que por el momento no tenemos un problema de multicolinealidad perfecta.
Sin embargo, es necesario realizar un analisis más de este.
Considere un analisis de multicolinealidad, para ello considere los siguientes factores, la $R^{2}$ a un nivel de 0.98, vista en el Cuadro \#3; y la matriz de correlaciones entre variables explicativas.

```{r, echo=TRUE}

cor(x=house$lotsize, y= house$bedrooms, method = c("pearson"))
cor(x=house$lotsize, y= house$bathrooms, method = c("pearson"))
cor(x=house$bedrooms, y= house$bathrooms, method = c("pearson"))


```

Visto los resultados de la matriz, vemos que si existe naja correlación entre varias variablesPor ellos ahora usaremos el analisis del indice K.

Procedemos en analsis del indice K donde sabemos que,

$$
K= \frac{\max_{valor \, propio}X'X}{\min_{valor \, propio}X'X}
$$

Donde el Indice K (IC) es $\sqrt{K}$, donde si

-   Si 10 \< IC \< 30 hay multicolinealidad modera fuerte.

-   Si IC\> 30 hay un problema serio de multicolinealidad.

```{r}

#Se crea la matriz de variables explicativas

X <- as.matrix(cbind(house$lotsize, house$bedrooms, house$bathrooms))

#Se computa X'X

X_prima_X <- t(X)%*%X

#Se obtienen los valores propis de la matriz X'X con la función eigen (base de R), se usa la opción only.values = TRUE para que solo brinde los valores propios y no sus vectores asociados
valores_propios<-eigen(X_prima_X, only.values = TRUE)

#Se computa el índice de condición K
indice_condicion_k<-sqrt(max(valores_propios$values))/sqrt(min(valores_propios$values))

indice_condicion_k
```

El Indice K nos da un número extremadamente alto, por lo que se tiene un problema muy serio de multicolinealidad.

### 3.5 Corrección a las Pruebas

### 3.6 Comparación
